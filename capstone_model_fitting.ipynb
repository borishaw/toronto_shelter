{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone - Toronto Shelter Occupancy Prediction Model Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Decomposing\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Model Evaluations\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data csv\n",
    "df = pd.read_csv('data/shelter_occupancy_cleaned.csv').drop(['Unnamed: 0'], axis=1)\n",
    "coor_df = pd.read_csv('data/shelter_coordinates.csv').drop(['Unnamed: 0'], axis=1)\n",
    "weather_df = pd.read_csv('data/toronto_weather.csv').drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging data frames\n",
    "df = pd.merge(df, coor_df, how='left', on='SHELTER_POSTAL_CODE')\n",
    "df = pd.merge(df, weather_df, how='left', on='OCCUPANCY_DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting categorical data to dummy variables\n",
    "df = pd.get_dummies(df, columns=['SECTOR', 'sublocality', 'Week_Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unneeded features before fitting\n",
    "df = df.drop([\n",
    "    'FACILITY_NAME', 'OCCUPANCY_DATE', 'ORGANIZATION_NAME', 'PROGRAM_NAME', 'SHELTER_ADDRESS', 'SHELTER_CITY',\n",
    "    'SHELTER_NAME', 'SHELTER_POSTAL_CODE', 'SHELTER_PROVINCE','lat', 'lng', 'OCCUPANCY',\n",
    "    'Week_Day_Int'\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining occupancy level (dependent variable)\n",
    "# 1 if occupancy rate is higher than 100%\n",
    "df['OCCUPANCY_LEVEL'] = df.OCCUPANCY_RATE.apply(lambda x : 1 if x >=1 else 0)\n",
    "df = df.drop(['OCCUPANCY_RATE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Mean Temp (Â°C)', 'Total Precip (mm)'], dtype='object')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It seems that the historical weather data contains null values\n",
    "df.columns[df.isna().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows with null weather data\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data for model fitting\n",
    "\n",
    "# Independent variables are shelter data (capacity, day of the week, location, weather, etc.)\n",
    "X = df.loc[:, 'CAPACITY':'Week_Day_WED']\n",
    "\n",
    "# Dependent variable is weather a shelter is full (1 indicates a shelter is full, 0 indicates otherwise)\n",
    "y = df.OCCUPANCY_LEVEL\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Fitting Models\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6368167998303047\n"
     ]
    }
   ],
   "source": [
    "# Trying to fit a Logistic Regression model with default settings\n",
    "logit = LogisticRegression().fit(X_train, y_train)\n",
    "print(f'Accuracy: {logit.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.609166\n",
       "0    0.390834\n",
       "Name: OCCUPANCY_LEVEL, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of full and non-full records\n",
    "y.value_counts() / y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "61% of the records in the data reach full occupancy. A accuracy score of 64% is only slightly better than pure chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score: 0.6518589841783925\n",
      "Recall Score: 0.8653013798111837\n",
      "F1 Score: 0.7435660617558224\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall & F1 Score \n",
    "y_pred = logit.predict(X_test)\n",
    "print(f'Precision Score: {precision_score(y_test, y_pred)}')\n",
    "print(f'Recall Score: {recall_score(y_test, y_pred)}')\n",
    "print(f'F1 Score: {f1_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.28      0.38     22147\n",
      "           1       0.65      0.87      0.74     34425\n",
      "\n",
      "    accuracy                           0.64     56572\n",
      "   macro avg       0.61      0.57      0.56     56572\n",
      "weighted avg       0.62      0.64      0.60     56572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial logistic model shows an **F1** score of **0.74**. This will be used as a baseline to compare with other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying an SVM model with data scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.37      0.46     22223\n",
      "           1       0.68      0.85      0.75     34595\n",
      "\n",
      "    accuracy                           0.66     56818\n",
      "   macro avg       0.64      0.61      0.60     56818\n",
      "weighted avg       0.65      0.66      0.64     56818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rbf_svc = SVC(kernel='rbf').fit(X_train, y_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_pred = rbf_svc.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM model is able to achieve an **F1** score of **0.66**, which is a minor improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=0.9, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decomposing with PCA\n",
    "# Selecting the first 90% Principal Components\n",
    "pca = PCA(0.9)\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 22)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the size of the Principal Components\n",
    "pca.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the importance of each Principal Component\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.bar(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the first **15** components in PCA are able to explain 90% of the significance. It'd be reasonable to set the number of components to **15** in further model fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62556701 0.6228866  0.62219014 0.62541254 0.62974422]\n"
     ]
    }
   ],
   "source": [
    "# Pipeline to find better models\n",
    "pipe = make_pipeline(StandardScaler(), PCA(n_components=15), LogisticRegression())\n",
    "\n",
    "# Use cross validation score to check if overfitting\n",
    "print(cross_val_score(pipe, X_train, y_train, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying logistic regression grid search with different hyperparameters\n",
    "estimators = [('scaler', StandardScaler()),\n",
    "              ('model', LogisticRegression())]\n",
    "\n",
    "pipe_logit = Pipeline(estimators)\n",
    "params_logit = [\n",
    "    {'model': [LogisticRegression()],\n",
    "     'scaler': [None, StandardScaler(), MinMaxScaler()],\n",
    "     'model__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "     'model__penalty': ['l1','l2']}\n",
    "]\n",
    "\n",
    "grid_logit = GridSearchCV(pipe_logit, params_logit, cv=5)\n",
    "grid_logit_fitted = grid_logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('model',\n",
      "                 LogisticRegression(C=1, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=None,\n",
      "                                    solver='warn', tol=0.0001, verbose=0,\n",
      "                                    warm_start=False))],\n",
      "         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "grid_logit_fitted.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that a model with default setting **(L2, C=1)** and scaled data with **Standard Scaler** yields the best result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 348 candidates, totalling 1740 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:   29.3s\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed:   32.0s\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed:   34.4s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:   36.5s\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:   39.4s\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed:   42.4s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   45.9s\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed:   50.1s\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:   53.8s\n",
      "[Parallel(n_jobs=-1)]: Done 537 tasks      | elapsed:   59.2s\n",
      "[Parallel(n_jobs=-1)]: Done 570 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 605 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 677 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 714 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 753 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 833 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 917 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 960 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1050 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1097 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1193 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1293 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1344 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1397 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1505 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1560 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1617 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1674 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1733 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1740 out of 1740 | elapsed:  6.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7395177826486601"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting different Random Forest models\n",
    "pipe_rf = Pipeline([('scale', StandardScaler()), ('pca', PCA()), ('model', RandomForestClassifier())])\n",
    "\n",
    "param_rf = [\n",
    "    {'scale':[StandardScaler(), None], 'pca':[None], 'model':[RandomForestClassifier()],\n",
    "    'model__max_depth':np.arange(1,30)},\n",
    "    {'scale':[StandardScaler(), None], 'pca':[PCA()], 'model':[RandomForestClassifier()],\n",
    "    'model__max_depth':np.arange(1,30),\n",
    "    'pca__n_components':[3, 5, 10, 15, 20]}\n",
    "]\n",
    "\n",
    "grid_rf = GridSearchCV(pipe_rf, param_rf, cv=5, verbose=10, n_jobs=-1)\n",
    "grid_rf_fitted = grid_rf.fit(X_train, y_train)\n",
    "\n",
    "grid_rf_fitted.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scale', None),\n",
       "                ('pca',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=5,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('model',\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=14,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=10, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf_fitted.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.56      0.63     22229\n",
      "           1       0.75      0.85      0.80     34343\n",
      "\n",
      "    accuracy                           0.74     56572\n",
      "   macro avg       0.73      0.71      0.71     56572\n",
      "weighted avg       0.74      0.74      0.73     56572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = grid_rf_fitted.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Random Forest model with a number of trees of **10**, with data decomposed with **5** principal components, yields the best result. It is able to achieve an **F1** score of **0.80** and accuracy rate of **74%**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
